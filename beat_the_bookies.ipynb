{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRxeI7EOx9k_"
   },
   "source": [
    "# Beat The Bookies: Predicting EPL Matches\n",
    "_Team C_\n",
    "\n",
    "__Mohammad Ali Syed, Abdul Al-Fahim, Dylan Hoi, Henry Chen, Chris Wong & Yolanne Lee__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOcQFZzsgHWK"
   },
   "source": [
    "**Contents:**\n",
    "\n",
    "[Section 1](#section1): Introduction\n",
    "\n",
    "[Section 2](#section2): Data Import\n",
    "\n",
    "[Section 3](#section3): Data Transformation & Exploration\n",
    "\n",
    "[Section 4](#section4): Methodology Overview\n",
    "\n",
    "[Section 5](#section5): Model Training & Validation\n",
    "\n",
    "[Section 6](#section6): Results\n",
    "\n",
    "[Section 7](#section7): Final Predictions on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-EqnUuI8gWm"
   },
   "source": [
    "## Introduction\n",
    "<a name='section1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-EqnUuI8gWm"
   },
   "source": [
    "## Data Import\n",
    "<a name='section2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, classification_report,confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>Referee</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16/08/08</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>H Webb</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16/08/08</td>\n",
       "      <td>Bolton</td>\n",
       "      <td>Stoke</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>C Foy</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16/08/08</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Blackburn</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>A Marriner</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16/08/08</td>\n",
       "      <td>Hull</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>P Walton</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16/08/08</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>M Atkinson</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date       HomeTeam   AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n",
       "0  16/08/08        Arsenal  West Brom     1     0   H     1     0   H   \n",
       "1  16/08/08         Bolton      Stoke     3     1   H     3     0   H   \n",
       "2  16/08/08        Everton  Blackburn     2     3   A     1     1   D   \n",
       "3  16/08/08           Hull     Fulham     2     1   H     1     1   D   \n",
       "4  16/08/08  Middlesbrough  Tottenham     2     1   H     0     0   D   \n",
       "\n",
       "      Referee  HS  AS  HST  AST  HF  AF  HC  AC  HY  AY  HR  AR  \n",
       "0      H Webb  24   5   14    4  11   8   7   5   0   0   0   0  \n",
       "1       C Foy  14   8    8    2  13  12   4   3   1   2   0   0  \n",
       "2  A Marriner  10  15    5   11  11   9   3   5   2   2   0   0  \n",
       "3    P Walton  11  12    6    6  10   9   5   6   3   0   0   0  \n",
       "4  M Atkinson  14   8   10    5  11  12   7   9   1   2   0   0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "\n",
    "#Change this to your directory\n",
    "dirName = 'Data_Files/'\n",
    "filePath = dirName + 'epl-training.csv'\n",
    "\n",
    "data = pd.read_csv(filePath)\n",
    "#Remove empty nan columns at the end\n",
    "data = data.iloc[:, 0:22]\n",
    "pd.set_option('display.max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_b63a_ejYMVK"
   },
   "source": [
    "## Data Transformation & Exploration\n",
    "<a name='section3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "\n",
    "def corr_matrix(X, feature):\n",
    "    corr= X.corr()\n",
    "    corr_y = abs(corr[feature])\n",
    "    highest_corr = corr_y[corr_y >0.4]\n",
    "    highest_corr.sort_values(ascending=True)\n",
    "    return highest_corr\n",
    "\n",
    "def rf_model(X_train, X_test, y_train, y_test):\n",
    "    rf=RandomForestClassifier(random_state = 42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    preds = rf.predict(X_test)\n",
    "    accuracy = calc_accuracy(preds, y_test)\n",
    "    return rf, preds, accuracy\n",
    "\n",
    "def feat_importances(X_train, rf):\n",
    "    feature_importances = list(zip(X_train, rf.feature_importances_))\n",
    "    feature_importances_ranked = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "    return feature_importances_ranked\n",
    "\n",
    "def select_feat(X_train, y_train):\n",
    "    feature_selector = SelectFromModel(estimator=RandomForestClassifier(random_state = 42)).fit(X_train, y_train)\n",
    "    selected_feat= X_train.columns[(feature_selector.get_support())]\n",
    "    return selected_feat\n",
    "\n",
    "def calc_accuracy(preds, labels):\n",
    "    accuracy = accuracy_score(labels, preds) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6396761133603239"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################# Feature Visualisation\n",
    "#Visualise correlations between different statistics\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "#Sort data by teams\n",
    "teams = {}\n",
    "referees = {}\n",
    "for i in data.groupby('HomeTeam').mean().T.columns:\n",
    "    teams[i] = []\n",
    "for i in data.groupby('Referee').mean().T.columns:\n",
    "    referees[i] = []\n",
    "\n",
    "#Compute summary stats per team\n",
    "temp = data[(data[\"HomeTeam\"] == \"Arsenal\")]\n",
    "temp_ = temp.iloc[:, [3,6,10,12,14,16,18,20]]\n",
    "temp_.sum()\n",
    "\n",
    "#make data frame for both away teams and home teams for summary stats\n",
    "\n",
    "test = temp.iloc[:, 5]\n",
    "test.value_counts()[0]/len(test) #note the 0 index is H so may need to be changed for away \n",
    "# temp2 = data[(data[\"AwayTeam\"] == \"Arsenal\")]\n",
    "# temp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTHG: \n",
      "FTHG    1.000000\n",
      "HTHG    0.686279\n",
      "HST     0.447116\n",
      "Name: FTHG, dtype: float64\n",
      "FTAG: \n",
      "FTAG    1.000000\n",
      "HTAG    0.689755\n",
      "AST     0.455887\n",
      "Name: FTAG, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Correlation matrix between full time goals and other features\n",
    "highest_corr = corr_matrix(data, \"FTHG\")\n",
    "print(\"FTHG: \\n\" + str(highest_corr))\n",
    "\n",
    "highest_corr = corr_matrix(data, \"FTAG\")\n",
    "print(\"FTAG: \\n\" + str(highest_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset into input and output data\n",
    "\n",
    "#Output variable\n",
    "y = data.iloc[:, 5:6]\n",
    "#Reformat y to make it suitable for LabelEncoder\n",
    "y = np.array(y).reshape(len(y))\n",
    "#Encode y\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "#Input variables\n",
    "#Remove give away columns such as goals scored\n",
    "data_filtered = data.drop(labels = data.columns[[3, 4, 5, 6, 7, 8]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "\n",
    "#Dates\n",
    "data_filtered['Date'] = pd.to_datetime(data_filtered['Date'])\n",
    "#year has been removed as we need to predict future results -> https://towardsdatascience.com/machine-learning-with-datetime-feature-engineering-predicting-healthcare-appointment-no-shows-5e4ca3a85f96\n",
    "data_filtered['Month'] = data_filtered['Date'].dt.month\n",
    "data_filtered['Week'] = data_filtered['Date'].dt.isocalendar().week\n",
    "data_filtered['Day'] = data_filtered['Date'].dt.day\n",
    "#Extract encoded dates\n",
    "dates_split = data_filtered.iloc[:, 16:19]\n",
    "#Remove encoded dates and original date column\n",
    "data_filtered = data_filtered.drop(labels = data_filtered.columns[[0, 16, 17, 18]], axis = 1)\n",
    "\n",
    "#Encode categorical data\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "#Teams\n",
    "home_t = data_filtered.iloc[:, 0:1]\n",
    "home_t = encoder.fit_transform(home_t)\n",
    "\n",
    "away_t = data_filtered.iloc[:, 1:2]\n",
    "away_t = encoder.fit_transform(away_t)\n",
    "data_filtered = data_filtered.drop(labels = data_filtered.columns[[0,1]], axis = 1)\n",
    "\n",
    "#Referees \n",
    "ref = data_filtered.iloc[:, 0:1]\n",
    "ref = encoder.fit_transform(ref)\n",
    "data_filtered = data_filtered.drop(labels = data_filtered.columns[[0]], axis = 1)\n",
    "\n",
    "#Re-stack columns\n",
    "data_filtered = data_filtered.join(pd.DataFrame(ref.toarray()), rsuffix = '_ref')\n",
    "data_filtered = data_filtered.join(pd.DataFrame(home_t.toarray()), rsuffix = '_home')\n",
    "data_filtered = data_filtered.join(pd.DataFrame(away_t.toarray()), rsuffix = '_away')\n",
    "data_filtered = dates_split.join(data_filtered)\n",
    "data_filtered.columns = data_filtered.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on entire featureset: 57.827260458839405%\n"
     ]
    }
   ],
   "source": [
    "#Train model on entire featureset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_filtered, y, test_size=0.3, random_state=42)\n",
    "rf, preds, base_accuracy = rf_model(X_train, X_test, y_train, y_test)\n",
    "print(\"Accuracy on entire featureset: \" + str(base_accuracy) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without Referee: 57.962213225371116%\n",
      "Difference from before: 0.13495276653171118%\n"
     ]
    }
   ],
   "source": [
    "#Train model without Referee feature\n",
    "data_filtered_no_ref = data_filtered.iloc[:, 0:15].join(data_filtered.iloc[:, 58:])\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_filtered_no_ref, y, test_size=0.3, random_state=42)\n",
    "rf, preds, accuracy = rf_model(X_train, X_test, y_train, y_test)\n",
    "print(\"Accuracy without Referee: \" + str(accuracy) + \"%\")\n",
    "print(\"Difference from before: \" + str(accuracy - base_accuracy) + \"%\")\n",
    "#Ref is having negative impact so remove\n",
    "data_filtered = data_filtered_no_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without Dates: 56.81511470985156%\n",
      "Difference from before: -1.012145748987848%\n"
     ]
    }
   ],
   "source": [
    "#Train model without Date feature\n",
    "data_filtered_no_date = data_filtered.iloc[:, 3:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_filtered_no_date, y, test_size=0.3, random_state=42)\n",
    "rf, preds, accuracy = rf_model(X_train, X_test, y_train, y_test)\n",
    "print(\"Accuracy without Dates: \" + str(accuracy) + \"%\")\n",
    "print(\"Difference from before: \" + str(accuracy - base_accuracy) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on all game stats: 55.06072874493927%\n"
     ]
    }
   ],
   "source": [
    "#Train model on only in game stats to identify most important ones\n",
    "data_filtered_only_game_stats = data_filtered.iloc[:, 3:15]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_filtered_only_game_stats, y, test_size=0.3, random_state=42)\n",
    "rf, preds, all_stats_accuracy = rf_model(X_train, X_test, y_train, y_test)\n",
    "print(\"Accuracy on all game stats: \" + str(all_stats_accuracy) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances: \n",
      "Feature: HST                                 Importance: 0.13373568693956137\n",
      "Feature: AST                                 Importance: 0.11086929727346594\n",
      "Feature: HS                                  Importance: 0.10711965963253876\n",
      "Feature: AS                                  Importance: 0.10459574408160308\n",
      "Feature: AF                                  Importance: 0.10278875719257885\n",
      "Feature: HF                                  Importance: 0.10274903136845186\n",
      "Feature: HC                                  Importance: 0.09664473425445547\n",
      "Feature: AC                                  Importance: 0.09167319027635455\n",
      "Feature: AY                                  Importance: 0.06454575651360132\n",
      "Feature: HY                                  Importance: 0.0615627757744895\n",
      "Feature: AR                                  Importance: 0.012278852078380604\n",
      "Feature: HR                                  Importance: 0.011436514614518712\n",
      "\n",
      "Confusion Matrix: \n",
      "[[244  46 127]\n",
      " [134  50 186]\n",
      " [118  55 522]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.59      0.53       417\n",
      "           1       0.33      0.14      0.19       370\n",
      "           2       0.63      0.75      0.68       695\n",
      "\n",
      "    accuracy                           0.55      1482\n",
      "   macro avg       0.48      0.49      0.47      1482\n",
      "weighted avg       0.51      0.55      0.52      1482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Visualise and analyse initial results\n",
    "\n",
    "#Display feature importances in descending order\n",
    "feature_importances = feat_importances(X_train, rf)\n",
    "print(\"Feature Importances: \")\n",
    "[print('Feature: {:35} Importance: {}'.format(*pair)) for pair in feature_importances];\n",
    "\n",
    "print(\"\\nConfusion Matrix: \")\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print(\"\\nClassification Report: \")\n",
    "print(classification_report(y_test, preds))\n",
    "#Important note: AF/HF rank higher than HC/AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Feature Selection\n",
    "#change names and display selected features more nicely, ideally with their importance, gini impurity...\n",
    "selected_feat = select_feat(X_train, y_train)\n",
    "print(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on reduced in game stats: 54.79082321187584%\n",
      "Difference compared to all game stats: -0.26990553306342946%\n",
      "\n",
      "Confusion Matrix: \n",
      "[[234  39 144]\n",
      " [107  64 199]\n",
      " [118  63 514]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.56      0.53       417\n",
      "           1       0.39      0.17      0.24       370\n",
      "           2       0.60      0.74      0.66       695\n",
      "\n",
      "    accuracy                           0.55      1482\n",
      "   macro avg       0.50      0.49      0.48      1482\n",
      "weighted avg       0.52      0.55      0.52      1482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train model on selected game stats only\n",
    "indexes = []\n",
    "for feat in selected_feat:\n",
    "    indexes.append(data_filtered_only_game_stats.columns.get_loc(feat))\n",
    "    \n",
    "data_filtered_filtered_game_stats = data_filtered_only_game_stats.iloc[:, indexes]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_filtered_filtered_game_stats, y, test_size=0.3, random_state=42)\n",
    "rf, preds, reduced_stats_accuracy = rf_model(X_train, X_test, y_train, y_test)\n",
    "print(\"Accuracy on reduced in game stats: \" + str(reduced_stats_accuracy) + \"%\")\n",
    "print(\"Difference compared to all game stats: \" + str(reduced_stats_accuracy - all_stats_accuracy) + \"%\")\n",
    "\n",
    "print(\"\\nConfusion Matrix: \")\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print(\"\\nClassification Report: \")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation of new featureset/tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produce new dataset\n",
    "#Fix column names\n",
    "#Restack teams and dates\n",
    "\n",
    "#Original teams are needed to be able to compute priors\n",
    "data_new = data.iloc[:, [1, 2]].join(data_filtered_filtered_game_stats)\n",
    "data_new = dates_split.join(data_new)\n",
    "\n",
    "#Stack previously removed giveaway columns\n",
    "data_new = data_new.join(data.iloc[:, [3, 4, 6, 7, 8]])\n",
    "\n",
    "#Feature engineer second half goals\n",
    "#Second half home goals\n",
    "SHHG = np.array(data.iloc[:, [3]]) - np.array(data.iloc[:, [6]])\n",
    "#Second half away goals\n",
    "SHAG = np.array(data.iloc[:, [4]]) - np.array(data.iloc[:, [7]])\n",
    "data_new['SHHG'] = pd.DataFrame(SHHG)\n",
    "data_new['SHAG'] = pd.DataFrame(SHAG)\n",
    "data_new.columns = data_new.columns.astype(str)\n",
    "\n",
    "#One hot encode dates? -> make the one hot columns but dont stack now, will be better to do after priors all together with teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTHG: \n",
      "HST     0.447116\n",
      "FTHG    1.000000\n",
      "HTHG    0.686279\n",
      "SHHG    0.769173\n",
      "Name: FTHG, dtype: float64\n",
      "FTAG: \n",
      "AST     0.455887\n",
      "FTAG    1.000000\n",
      "HTAG    0.689755\n",
      "SHAG    0.777641\n",
      "Name: FTAG, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#See if second half goals column we added has significant correlation to total goals\n",
    "highest_corr = corr_matrix(data_new, \"FTHG\")\n",
    "print(\"FTHG: \\n\" + str(highest_corr))\n",
    "\n",
    "highest_corr = corr_matrix(data_new, \"FTAG\")\n",
    "print(\"FTAG: \\n\" + str(highest_corr))\n",
    "#Second half goals do have very strong correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90xVEDPEp5Js"
   },
   "source": [
    "## Methodology Overview\n",
    "<a name='section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOxVov2mqGZ-"
   },
   "source": [
    "## Model Training & Validation\n",
    "<a name='section5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_aPyBUwqMAD"
   },
   "source": [
    "## Results\n",
    "<a name='section6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2XDY1oOAyEZ"
   },
   "source": [
    "## Final Predictions on Test Set\n",
    "<a name='section7'></a>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CW1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
