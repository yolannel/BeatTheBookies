{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRxeI7EOx9k_"
   },
   "source": [
    "# Beat The Bookies: Predicting EPL Matches\n",
    "_Team C_\n",
    "\n",
    "__Mohammad Ali Syed, Abdul Al-Fahim, Dylan Hoi, Henry Chen, Chris Wong & Yolanne Lee__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOcQFZzsgHWK"
   },
   "source": [
    "**Contents:**\n",
    "\n",
    "[Section 1](#section1): Introduction\n",
    "\n",
    "[Section 2](#section2): Data Import\n",
    "\n",
    "[Section 3](#section3): Data Transformation & Exploration\n",
    "\n",
    "[Section 4](#section4): Methodology Overview\n",
    "\n",
    "[Section 5](#section5): Model Training & Validation\n",
    "\n",
    "[Section 6](#section6): Results\n",
    "\n",
    "[Section 7](#section7): Final Predictions on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-EqnUuI8gWm"
   },
   "source": [
    "## Introduction\n",
    "<a name='section1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-EqnUuI8gWm"
   },
   "source": [
    "## Data Import\n",
    "<a name='section2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, classification_report,confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#For Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "\n",
    "#For Model Selection\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, KFold, RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>Referee</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16/08/08</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>H Webb</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16/08/08</td>\n",
       "      <td>Bolton</td>\n",
       "      <td>Stoke</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>C Foy</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16/08/08</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Blackburn</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>A Marriner</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16/08/08</td>\n",
       "      <td>Hull</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>P Walton</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16/08/08</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>M Atkinson</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date       HomeTeam   AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n",
       "0  16/08/08        Arsenal  West Brom     1     0   H     1     0   H   \n",
       "1  16/08/08         Bolton      Stoke     3     1   H     3     0   H   \n",
       "2  16/08/08        Everton  Blackburn     2     3   A     1     1   D   \n",
       "3  16/08/08           Hull     Fulham     2     1   H     1     1   D   \n",
       "4  16/08/08  Middlesbrough  Tottenham     2     1   H     0     0   D   \n",
       "\n",
       "      Referee  HS  AS  HST  AST  HF  AF  HC  AC  HY  AY  HR  AR  \n",
       "0      H Webb  24   5   14    4  11   8   7   5   0   0   0   0  \n",
       "1       C Foy  14   8    8    2  13  12   4   3   1   2   0   0  \n",
       "2  A Marriner  10  15    5   11  11   9   3   5   2   2   0   0  \n",
       "3    P Walton  11  12    6    6  10   9   5   6   3   0   0   0  \n",
       "4  M Atkinson  14   8   10    5  11  12   7   9   1   2   0   0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "\n",
    "#Change this to your directory\n",
    "dirName = 'Data_Files/'\n",
    "filePath = dirName + 'epl-training.csv'\n",
    "\n",
    "data = pd.read_csv(filePath)\n",
    "#Remove empty nan columns at the end\n",
    "data = data.iloc[:, 0:22]\n",
    "pd.set_option('display.max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_b63a_ejYMVK"
   },
   "source": [
    "## Data Transformation & Exploration\n",
    "<a name='section3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "\n",
    "def corr_matrix(X, feature):\n",
    "    corr= X.corr()\n",
    "    corr_y = abs(corr[feature])\n",
    "    highest_corr = corr_y[corr_y >0.2]\n",
    "    highest_corr.sort_values(ascending=True)\n",
    "    return highest_corr\n",
    "\n",
    "def rf_model(X_train, X_test, y_train, y_test):\n",
    "    rf=RandomForestClassifier(random_state = 42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    preds = rf.predict(X_test)\n",
    "    accuracy = calc_accuracy(preds, y_test)\n",
    "    return rf, preds, accuracy\n",
    "\n",
    "def feat_importances(X_train, rf):\n",
    "    feature_importances = list(zip(X_train, rf.feature_importances_))\n",
    "    feature_importances_ranked = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "    return feature_importances_ranked\n",
    "\n",
    "def select_feat(X_train, y_train):\n",
    "    feature_selector = SelectFromModel(RandomForestClassifier(random_state = 42)).fit(X_train, y_train)\n",
    "    selected_feat= X_train.columns[(feature_selector.get_support())]\n",
    "    return selected_feat\n",
    "\n",
    "def calc_accuracy(preds, labels):\n",
    "    accuracy = accuracy_score(labels, preds) * 100\n",
    "    return accuracy\n",
    "\n",
    "def rf_tree_visualiser(rf, featuresetName, feature_names):\n",
    "    tree = rf.estimators_[10]  #Take 10th random tree\n",
    "    export_graphviz(tree, out_file = featuresetName + '.dot', feature_names = list(feature_names),\n",
    "                    rounded = True, proportion = False, \n",
    "                    precision = 2, filled = True, max_depth = 3)\n",
    "    call(['dot', '-Tpng', featuresetName + '.dot', '-o', featuresetName + '.png'],shell=True)\n",
    "    return featuresetName + '.png'\n",
    "\n",
    "def scatter(data, title, xlabel, ylabel):\n",
    "    # Assume data is an array of tuples\n",
    "    x, y = zip(*data)\n",
    "    # s is the area of the circles in the plot\n",
    "    plt.scatter(x, y, s=50)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "    \n",
    "# https://towardsdatascience.com/stop-one-hot-encoding-your-time-based-features-24c699face2f\n",
    "def transformation(column):\n",
    "    max_value = column.max()\n",
    "    sin_values = [math.sin((2*math.pi*x)/max_value) for x in list(column)]\n",
    "    cos_values = [math.cos((2*math.pi*x)/max_value) for x in list(column)]\n",
    "    return sin_values, cos_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set a frame with no defined index and a value that cannot be converted to a Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_ensure_valid_index\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   3162\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3163\u001b[1;33m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3164\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mis_empty_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m                 \u001b[1;31m# gh-17261\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36mis_empty_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[0mis_list_like_without_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m     \u001b[0mis_simple_empty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_list_like_without_dtype\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mis_none\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_simple_empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m         raise ValueError(\n\u001b[1;32m-> 1327\u001b[1;33m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11048/2823063410.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mteam_stats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Draw Rate\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mhome_team_stats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mteam\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mteam_stats\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m##causing problems\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m# Compute summary stats as away team\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3035\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3036\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3037\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3039\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3110\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3111\u001b[0m         \"\"\"\n\u001b[1;32m-> 3112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3113\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3114\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_ensure_valid_index\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   3166\u001b[0m                     \u001b[1;34m\"Cannot set a frame with no defined index \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3167\u001b[0m                     \u001b[1;34m\"and a value that cannot be converted to a Series\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3168\u001b[1;33m                 ) from err\n\u001b[0m\u001b[0;32m   3169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3170\u001b[0m             self._mgr = self._mgr.reindex_axis(\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set a frame with no defined index and a value that cannot be converted to a Series"
     ]
    }
   ],
   "source": [
    "############################################# Feature Visualisation\n",
    "# Visualise correlations between different statistics\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# Sort data by teams\n",
    "teams = {}\n",
    "referees = {}\n",
    "for i in data.groupby('HomeTeam').mean().T.columns:\n",
    "    teams[i] = []\n",
    "for i in data.groupby('Referee').mean().T.columns:\n",
    "    referees[i] = []\n",
    "\n",
    "# Team Summary Statistics\n",
    "home_team_stats = pd.DataFrame()\n",
    "away_team_stats = pd.DataFrame()\n",
    "\n",
    "teams = pd.unique(data[[\"HomeTeam\"]].values.ravel())\n",
    "\n",
    "for team in teams:\n",
    "    # Compute summary stats as home team\n",
    "    team_stats = data[(data[\"HomeTeam\"] == team)]\n",
    "    team_stats = team_stats.iloc[:, [3, 6, 10, 12, 14, 16, 18, 20]]\n",
    "    team_stats = team_stats.sum()\n",
    "\n",
    "    performance = data[(data[\"HomeTeam\"] == team)].iloc[:, 5]\n",
    "    num_vals = len(performance)\n",
    "    \n",
    "    performance = performance.value_counts()\n",
    "    performance_keys = performance.keys()\n",
    "    performance_values = performance.values\n",
    "    performance = zip(performance.keys(), performance.values)\n",
    "    \n",
    "    for key, value in performance:\n",
    "        metric = value/num_vals\n",
    "        \n",
    "        if key == \"H\":\n",
    "            team_stats[\"Win Rate\"] = metric\n",
    "            \n",
    "        elif key == \"A\":\n",
    "            team_stats[\"Lose Rate\"] = metric\n",
    "        \n",
    "        else:\n",
    "            team_stats[\"Draw Rate\"] = metric\n",
    "\n",
    "    home_team_stats[team] = pd.DataFrame(team_stats) ##causing problems\n",
    "\n",
    "    # Compute summary stats as away team\n",
    "    team_stats = data[(data[\"AwayTeam\"] == team)]\n",
    "    team_stats = team_stats.iloc[:, [4, 7, 11, 13, 15, 17, 19, 21]]\n",
    "    team_stats = team_stats.sum()\n",
    "\n",
    "    performance = data[(data[\"AwayTeam\"] == team)].iloc[:, 5]\n",
    "    num_vals = len(performance)\n",
    "\n",
    "    performance = performance.value_counts()\n",
    "    performance_keys = performance.keys()\n",
    "    performance_values = performance.values\n",
    "    performance = zip(performance.keys(), performance.values)\n",
    "    \n",
    "    for key, value in performance:\n",
    "        metric = value/num_vals\n",
    "        \n",
    "        if key == \"A\":\n",
    "            team_stats[\"Win Rate\"] = metric\n",
    "            \n",
    "        elif key == \"H\":\n",
    "            team_stats[\"Lose Rate\"] = metric\n",
    "        \n",
    "        else:\n",
    "            team_stats[\"Draw Rate\"] = metric\n",
    "\n",
    "\n",
    "    away_team_stats[team] = pd.DataFrame(team_stats)\n",
    "\n",
    "# Sort by strongest to weakest team, by win rate\n",
    "home_team_stats = home_team_stats.sort_values(by='Win Rate', axis=1, ascending=False)\n",
    "away_team_stats = away_team_stats.sort_values(by='Win Rate', axis=1, ascending=False)\n",
    "home_team_stats\n",
    "#Interesting to note, Man U ranked lower on every metric except fouls and yellow cards compared to Chelsea but had higher win rate -> could suggest the more aggressive the team, the higher the win rate\n",
    "# print(home_team_stats.iloc[:, 0])\n",
    "# print(away_team_stats.iloc[:, 0])\n",
    "# print(np.array(home_team_stats.iloc[:, 0]) - np.array(away_team_stats.iloc[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation matrix between full time goals and other features\n",
    "highest_corr = corr_matrix(data, \"FTHG\")\n",
    "print(\"FTHG: \\n\" + str(highest_corr))\n",
    "\n",
    "highest_corr = corr_matrix(data, \"FTAG\")\n",
    "print(\"FTAG: \\n\" + str(highest_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset into input and output data\n",
    "\n",
    "#Output variable\n",
    "y = data.iloc[:, 5:6]\n",
    "#Reformat y to make it suitable for LabelEncoder\n",
    "y = np.array(y).reshape(len(y))\n",
    "#Encode y\n",
    "y = LabelEncoder().fit_transform(y) #################this needs to be done separately for train/test\n",
    "#Input variables\n",
    "#Remove give away columns such as goals scored\n",
    "data_filtered = data.drop(labels = data.columns[[3, 4, 5, 6, 7, 8]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "\n",
    "#Dates\n",
    "data_filtered['Date'] = pd.to_datetime(data_filtered['Date'])\n",
    "#year has been removed as we need to predict future results -> https://towardsdatascience.com/machine-learning-with-datetime-feature-engineering-predicting-healthcare-appointment-no-shows-5e4ca3a85f96\n",
    "data_filtered['Month'] = data_filtered['Date'].dt.month\n",
    "data_filtered['Week'] = data_filtered['Date'].dt.isocalendar().week\n",
    "data_filtered['Day'] = data_filtered['Date'].dt.day\n",
    "#Extract encoded dates\n",
    "dates_split = data_filtered.iloc[:, 16:19]\n",
    "#Remove encoded dates and original date column\n",
    "data_filtered = data_filtered.drop(labels = data_filtered.columns[[0, 16, 17, 18]], axis = 1)\n",
    "\n",
    "#Encode categorical data\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "#Teams\n",
    "home_t = data_filtered.iloc[:, 0:1]\n",
    "home_t = encoder.fit_transform(home_t) #################does this need to be done separately?\n",
    "\n",
    "away_t = data_filtered.iloc[:, 1:2]\n",
    "away_t = encoder.fit_transform(away_t) #################does this need to be done separately?\n",
    "data_filtered = data_filtered.drop(labels = data_filtered.columns[[0,1]], axis = 1)\n",
    "\n",
    "#Referees \n",
    "ref = data_filtered.iloc[:, 0:1]\n",
    "ref = encoder.fit_transform(ref)       #################does this need to be done separately?\n",
    "data_filtered = data_filtered.drop(labels = data_filtered.columns[[0]], axis = 1)\n",
    "\n",
    "#Re-stack columns\n",
    "data_filtered = data_filtered.join(pd.DataFrame(ref.toarray()), rsuffix = '_ref')\n",
    "data_filtered = data_filtered.join(pd.DataFrame(home_t.toarray()), rsuffix = '_home')\n",
    "data_filtered = data_filtered.join(pd.DataFrame(away_t.toarray()), rsuffix = '_away')\n",
    "data_filtered = dates_split.join(data_filtered)\n",
    "data_filtered.columns = data_filtered.columns.astype(str)\n",
    "data_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train model on entire featureset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_filtered, y, test_size=0.3, random_state=42)\n",
    "rf, preds, base_accuracy = rf_model(X_train, X_test, y_train, y_test)\n",
    "print(\"Accuracy on entire featureset: \" + str(base_accuracy) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print rf tree N.B. may not work without importing graphviz, random forest images will be on GitHub\n",
    "Image(filename = rf_tree_visualiser(rf, 'featureSetTree', data_filtered.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model without Referee feature\n",
    "data_filtered_no_ref = data_filtered.iloc[:, 0:15].join(data_filtered.iloc[:, 58:])\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_filtered_no_ref, y, test_size=0.3, random_state=42)\n",
    "rf, preds, accuracy = rf_model(X_train, X_test, y_train, y_test)\n",
    "print(\"Accuracy without Referee: \" + str(accuracy) + \"%\")\n",
    "print(\"Difference from before: \" + str(accuracy - base_accuracy) + \"%\")\n",
    "#Ref is having negative impact so remove\n",
    "data_filtered = data_filtered_no_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print rf tree (no ref)\n",
    "Image(filename = rf_tree_visualiser(rf, 'featureSetTreeNoRef', data_filtered_no_ref.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model without Date feature\n",
    "data_filtered_no_date = data_filtered.iloc[:, 3:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_filtered_no_date, y, test_size=0.3, random_state=42)\n",
    "rf, preds, accuracy = rf_model(X_train, X_test, y_train, y_test)\n",
    "print(\"Accuracy without Dates: \" + str(accuracy) + \"%\")\n",
    "print(\"Difference from before: \" + str(accuracy - base_accuracy) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print rf tree (no dates)\n",
    "Image(filename = rf_tree_visualiser(rf, 'featureSetTreeNoDate', data_filtered_no_date.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model on only in-game stats to identify most important ones\n",
    "data_filtered_only_game_stats = data_filtered.iloc[:, 3:15]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_filtered_only_game_stats, y, test_size=0.3, random_state=42)\n",
    "rf, preds, all_stats_accuracy = rf_model(X_train, X_test, y_train, y_test)\n",
    "print(\"Accuracy on all in-game stats: \" + str(all_stats_accuracy) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise and analyse initial results\n",
    "\n",
    "#Display feature importances in descending order\n",
    "feature_importances = feat_importances(X_train, rf)\n",
    "print(\"Feature Importances: \")\n",
    "[print('Feature: {:35} Importance: {}'.format(*pair)) for pair in feature_importances];\n",
    "\n",
    "print(\"\\nConfusion Matrix: \")\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print(\"\\nClassification Report: \")\n",
    "print(classification_report(y_test, preds))\n",
    "#Important note: AF/HF rank higher than HC/AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise feature importance\n",
    "scatter(feature_importances, \"Feature importances\", \"Feature\", \"Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Pearson Correlation Heatmap to see the top 10 features related to the match result FTR\n",
    "\n",
    "def plotGraph(X_all, Y_all):\n",
    "\n",
    "    train_data=pd.concat([X_all,Y_all],axis=1)\n",
    "\n",
    "    #FTR correlation matrix\n",
    "    plt.figure(figsize=(12,12))\n",
    "    k = 11 # number of variables for heatmap\n",
    "    cols = abs(train_data.astype(float).corr()).nlargest(k, 'FTR')['FTR'].index\n",
    "    cm = np.corrcoef(train_data[cols].values.T)\n",
    "    sns.set(font_scale=1.25)\n",
    "    hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 12}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "    plt.show()\n",
    "\n",
    "attributes = data.drop(['Date','HomeTeam', 'AwayTeam', 'Referee','FTR'],1)\n",
    "attributes['HTR'] = attributes['HTR'].map({'H':1,'A':0,'D':2})\n",
    "label = data['FTR']\n",
    "label = label.map({'H':1,'A':0,'D':2})\n",
    "plotGraph(attributes,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "#change names and display selected features more nicely, ideally with their importance, gini impurity...\n",
    "selected_feat = select_feat(X_train, y_train)\n",
    "print(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model on selected in-game stats only\n",
    "indexes = []\n",
    "for feat in selected_feat:\n",
    "    indexes.append(data_filtered_only_game_stats.columns.get_loc(feat))\n",
    "    \n",
    "data_filtered_filtered_game_stats = data_filtered_only_game_stats.iloc[:, indexes]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_filtered_filtered_game_stats, y, test_size=0.3, random_state=42)\n",
    "rf, preds, reduced_stats_accuracy = rf_model(X_train, X_test, y_train, y_test)\n",
    "print(\"Accuracy on reduced in-game stats: \" + str(reduced_stats_accuracy) + \"%\")\n",
    "print(\"Difference compared to all in-game stats: \" + str(reduced_stats_accuracy - all_stats_accuracy) + \"%\")\n",
    "\n",
    "print(\"\\nConfusion Matrix: \")\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print(\"\\nClassification Report: \")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation of new featureset/tree\n",
    "data_filtered_filtered_game_stats.plot(kind='hist', subplots=True, sharex=False, sharey=False, bins=50, layout=(2,4), figsize=(12, 6))\n",
    "data_filtered_filtered_game_stats.plot(kind='box', subplots=True, layout=(2,4), sharex=False, sharey=False, figsize=(12, 6))\n",
    "data_filtered_filtered_game_stats.plot(kind='density', subplots=True, layout=(2,4), sharex=False, sharey=False, figsize=(12, 6))\n",
    "Image(filename = rf_tree_visualiser(rf, 'selectedFeatureSetTree', data_filtered_filtered_game_stats.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produce new dataset\n",
    "#Fix column names\n",
    "#Restack teams and dates\n",
    "\n",
    "#Original teams are needed to be able to compute priors\n",
    "data_new = data.iloc[:, [1, 2]].join(data_filtered_filtered_game_stats)\n",
    "data_new = dates_split.join(data_new)\n",
    "\n",
    "#Stack previously removed giveaway columns\n",
    "data_new = data_new.join(data.iloc[:, [3, 4, 6, 7, 8]])\n",
    "\n",
    "#Feature engineer second half goals\n",
    "#Second half home goals\n",
    "SHHG = np.array(data.iloc[:, [3]]) - np.array(data.iloc[:, [6]])\n",
    "#Second half away goals\n",
    "SHAG = np.array(data.iloc[:, [4]]) - np.array(data.iloc[:, [7]])\n",
    "data_new['SHHG'] = pd.DataFrame(SHHG)\n",
    "data_new['SHAG'] = pd.DataFrame(SHAG)\n",
    "data_new.columns = data_new.columns.astype(str)\n",
    "data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See if second half goals have significant correlation to total goals\n",
    "highest_corr = corr_matrix(data_new, \"FTHG\")\n",
    "print(\"FTHG: \\n\" + str(highest_corr))\n",
    "\n",
    "highest_corr = corr_matrix(data_new, \"FTAG\")\n",
    "print(\"FTAG: \\n\" + str(highest_corr))\n",
    "#Second half goals do have very strong correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing priors\n",
    "#Number of previous wins\n",
    "goal_difference=[]\n",
    "FTR_away=0\n",
    "FTR_home=0\n",
    "draw=0\n",
    "\n",
    "#calculating difference in goals \n",
    "for j in range(0,len(data_new)):\n",
    "    goal_difference.append(data_new['FTHG'].iloc[j]-data_new['FTAG'].iloc[j])\n",
    "\n",
    "#Assign home,away or draw label for each outcome\n",
    "for i in range(0,len(goal_difference)):\n",
    "    if goal_difference[i]<0:\n",
    "        goal_difference[i]='A'\n",
    "        FTR_away=FTR_away+1\n",
    "    elif goal_difference[i]>0:\n",
    "        goal_difference[i]='H'\n",
    "        FTR_home=FTR_home+1\n",
    "    else:\n",
    "        goal_difference[i]='D'\n",
    "        draw=draw+1\n",
    "        \n",
    "#create new column and print out values\n",
    "data_new['FTR']=goal_difference\n",
    "\n",
    "# #read in df from ratings (https://www.whoscored.com)\n",
    "# ratings_matrix = pd.read_pickle(\"./ratingsDF.pkl\")\n",
    "# # print(ratings_matrix)\n",
    "# rating_difference = []\n",
    "# # print(data_new[\"HomeTeam\"].unique())\n",
    "# # print(\"____\")\n",
    "# # print(ratings_matrix.index)\n",
    "# for i in range(0,len(data_new)):\n",
    "# #     print(ratings_matrix[\"mean\"].loc[data_new[\"HomeTeam\"].iloc[i]])\n",
    "#     rating_difference.append(ratings_matrix[\"mean\"].loc[data_new[\"HomeTeam\"].iloc[i]]-ratings_matrix[\"mean\"].loc[data_new[\"AwayTeam\"].iloc[i]])\n",
    "\n",
    "# for i in range(0,len(rating_difference)):\n",
    "#     if rating_difference[i]<-0.1:\n",
    "#         rating_difference[i]='A'\n",
    "#     elif rating_difference[i]>0.1:\n",
    "#         rating_difference[i]='H'\n",
    "#     else:\n",
    "#         rating_difference[i]='D'\n",
    "\n",
    "# rating_difference = pd.DataFrame(rating_difference)\n",
    "# # rating_difference.describe()\n",
    "# # data_new['RatingSkew']=goal_difference\n",
    "# data_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priors Feature Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Pearson Correlation Heatmap to extract the top 10 features \n",
    "# there are two pairs of data highly correlated (see details in report), \n",
    "# so we just pick [FTHG, FTAG, HS, AS, HR, AR] from the top 10 features,\n",
    "# additionally [Date, HomeTeam, AwayTeam, FTR], to derive our features.\n",
    "selectedAttributes = [\"Date\",\"HomeTeam\", \"AwayTeam\",\"FTR\",\"FTHG\",\"FTAG\",\"HS\",\"AS\",\"HR\",\"AR\"]\n",
    "training_data = raw_training_data[selectedAttributes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cumulative Full-time W/L Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Priors\n",
    "# Calculate cumulative Full-Time win-loss ratio for Home/Away teams prior to every match\n",
    "# TODO: Points-based results based on previous wins & losses \n",
    "# PHWL = Previous Home Team Win Loss Ratio\n",
    "# PAWL = Previous Away Team Win Loss Ratio\n",
    "\n",
    "def get_previousFTResults(playing_stat):\n",
    "    \n",
    "    # Create a dictionary with team names as keys\n",
    "    teams = {}\n",
    "    PHWL = []\n",
    "    PAWL = []\n",
    "    \n",
    "    for i in playing_stat.groupby('HomeTeam').mean().T.columns:\n",
    "        teams[i] = [] #Each team gets their own list\n",
    "\n",
    "    # the value corresponding to keys is a list containing the match result\n",
    "    for i in range(len(playing_stat)):\n",
    "        \n",
    "        #list of respective Home/Away team in match\n",
    "        match_ht = teams[playing_stat.iloc[i].HomeTeam]\n",
    "        match_at = teams[playing_stat.iloc[i].AwayTeam]\n",
    "        \n",
    "        #count no. of wins\n",
    "        \n",
    "        h_wins = Counter(match_ht)\n",
    "        a_wins = Counter(match_at)\n",
    "        \n",
    "        #h_wins = no. of home wins\n",
    "        #a_wins = no. of away wins\n",
    "        h_wins = h_wins['W']\n",
    "        a_wins = a_wins['W']\n",
    "        \n",
    "        #append W/L/D to respective teams\n",
    "        \n",
    "        if playing_stat.iloc[i].FTR == 'H':\n",
    "            match_ht.append('W')\n",
    "            match_at.append('L')\n",
    "        elif playing_stat.iloc[i].FTR == 'A':\n",
    "            match_at.append('W')\n",
    "            match_ht.append('L')\n",
    "        else:\n",
    "            match_at.append('D')\n",
    "            match_ht.append('D')\n",
    "       \n",
    "        h_wlRatio = h_wins / len(match_ht)\n",
    "        a_wlRatio = a_wins / len(match_at)\n",
    "        \n",
    "        #Home/Away cumulative WL ratios prior to every match\n",
    "        PHWL.append(h_wlRatio)\n",
    "        PAWL.append(a_wlRatio)\n",
    "        \n",
    "    data_new.loc[:,'PHWL'] = pd.Series(PHWL)\n",
    "    data_new.loc[:,'PAWL'] = pd.Series(PAWL)\n",
    "\n",
    "    return data_new\n",
    "\n",
    "\n",
    "#get_previousFTResults(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Cumulative Half-time W/L Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Priors\n",
    "# Calculate cumulative Half-Time win-loss ratio for Home/Away teams prior to every match\n",
    "# HHTR = Previous Home Half Time Results\n",
    "# AHTR = Previous Away Half Time Results\n",
    "\n",
    "def get_PreviousHTResults(playing_stat):\n",
    "    \n",
    "    # Create a dictionary with team names as keys\n",
    "    teams = {}\n",
    "    HHTR = []\n",
    "    AHTR = []\n",
    "    \n",
    "    for i in playing_stat.groupby('HomeTeam').mean().T.columns:\n",
    "        teams[i] = [] #Each team gets their own list\n",
    "\n",
    "    # the value corresponding to keys is a list containing the match result\n",
    "    for i in range(len(playing_stat)):\n",
    "        \n",
    "        #list of respective Home/Away team in match\n",
    "        match_ht = teams[playing_stat.iloc[i].HomeTeam]\n",
    "        match_at = teams[playing_stat.iloc[i].AwayTeam]\n",
    "        \n",
    "        #count no. of wins\n",
    "        \n",
    "        h_wins = Counter(match_ht)\n",
    "        a_wins = Counter(match_at)\n",
    "        \n",
    "        #h_wins = no. of home wins\n",
    "        #a_wins = no. of away wins\n",
    "        h_wins = h_wins['W']\n",
    "        a_wins = a_wins['W']\n",
    "        \n",
    "        #append W/L/D to respective teams\n",
    "        \n",
    "        if playing_stat.iloc[i].HTR == 'H':\n",
    "            match_ht.append('W')\n",
    "            match_at.append('L')\n",
    "        elif playing_stat.iloc[i].HTR == 'A':\n",
    "            match_at.append('W')\n",
    "            match_ht.append('L')\n",
    "        else:\n",
    "            match_at.append('D')\n",
    "            match_ht.append('D')\n",
    "            \n",
    "        h_wlRatio = h_wins / len(match_ht)\n",
    "        a_wlRatio = a_wins / len(match_at)\n",
    "       \n",
    "        #Home/Away cumulative WL ratios prior to every match\n",
    "        HHTR.append(h_wlRatio)\n",
    "        AHTR.append(a_wlRatio)\n",
    "        \n",
    "    data_new.loc[:,'HHTR'] = pd.Series(HHTR)\n",
    "    data_new.loc[:,'AHTR'] = pd.Series(AHTR)\n",
    "\n",
    "    return data_new\n",
    "\n",
    "\n",
    "#get_PreviousHTResults(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cumulative Full-Time goals scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Priors\n",
    "# Calculate Previous Full-Time Cumulative Goal \n",
    "# PHGS = Previous Home Goal Scored\n",
    "# PAGS = Previous Away Goal Scored\n",
    "\n",
    "def getPreviousCumulativeGoals(data):\n",
    "    teams = {}\n",
    "    PHGS = [] \n",
    "    PAGS = []   \n",
    "\n",
    "    # for each match\n",
    "    for i in range(len(data)):\n",
    "        if (i % 100000 == 0):\n",
    "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
    "                teams[name] = []\n",
    "\n",
    "        FTHG = data.iloc[i]['FTHG']\n",
    "        FTAG = data.iloc[i]['FTAG']\n",
    "\n",
    "        try:\n",
    "            pcgs_h = teams[data.iloc[i].HomeTeam].pop()\n",
    "            pcgs_a = teams[data.iloc[i].AwayTeam].pop()\n",
    "        except:\n",
    "            pcgs_h = 0\n",
    "            pcgs_a = 0\n",
    "\n",
    "        PHGS.append(pcgs_h)\n",
    "        PAGS.append(pcgs_a)\n",
    "#         print(PAGS)\n",
    "#         print(PHGS)\n",
    "        pcgs_h = pcgs_h + FTHG #Home team's previous goals scored before this match\n",
    "        teams[data.iloc[i].HomeTeam].append(pcgs_h)\n",
    "        pcgs_a = pcgs_a + FTAG #Away team's previous goals scored before this match\n",
    "        teams[data.iloc[i].AwayTeam].append(pcgs_a)\n",
    "\n",
    "    data_new.loc[:,'PHGS'] = pd.Series(PHGS)\n",
    "    data_new.loc[:,'PAGS'] = pd.Series(PAGS)\n",
    "    return data_new\n",
    "\n",
    "#getPreviousCumulativeGoals(data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4. Cumulative Half-time W/L Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Priors\n",
    "# Calculate Previous Shots in the match\n",
    "# PHS = Home teams previous match Shots, totaled over season\n",
    "# PAS = Away teams previous match Shots, totaled over season\n",
    "\n",
    "def getPreviousShots(data):\n",
    "    teams = {}\n",
    "    PHS = [] \n",
    "    PAS = []   \n",
    "\n",
    "    # for each match\n",
    "    for i in range(len(data)):\n",
    "        if (i % 100000 == 0):\n",
    "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
    "                teams[name] = []\n",
    "\n",
    "        HS = data.iloc[i]['HS']\n",
    "        AS = data.iloc[i]['AS']\n",
    "\n",
    "        try:\n",
    "            pcs_h = teams[data.iloc[i].HomeTeam].pop()\n",
    "            pcs_a = teams[data.iloc[i].AwayTeam].pop()\n",
    "        except:\n",
    "            pcs_h = 0\n",
    "            pcs_a = 0\n",
    "\n",
    "        PHS.append(pcs_h)\n",
    "        PAS.append(pcs_a)\n",
    "        pcs_h = pcs_h + HS #Home team's previous goals scored before this match\n",
    "        teams[data.iloc[i].HomeTeam].append(pcs_h)\n",
    "        pcs_a = pcs_a + AS #Away team's previous goals scored before this match\n",
    "        teams[data.iloc[i].AwayTeam].append(pcs_a)\n",
    "\n",
    "    data_new.loc[:,'PHS'] = pd.Series(PHS)\n",
    "    data_new.loc[:,'PAS'] = pd.Series(PAS)\n",
    "    return data_new\n",
    "\n",
    "#getPreviousShots(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Previous shots on target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Priors\n",
    "# Calculate Previous Shots on Target\n",
    "# PHSOT = Home teams Previous Shots on Target, totaled over season\n",
    "# PASOT = Away teams Previous Shots on Target, totaled over season\n",
    "\n",
    "def getPreviousShotsOnTarget(data):\n",
    "    teams = {}\n",
    "    PHSOT = [] \n",
    "    PASOT = []   \n",
    "\n",
    "    # for each match\n",
    "    for i in range(len(data)):\n",
    "        if (i % 100000 == 0):\n",
    "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
    "                teams[name] = []\n",
    "\n",
    "        HST = data.iloc[i]['HST']\n",
    "        AST = data.iloc[i]['AST']\n",
    "\n",
    "        try:\n",
    "            pcsot_h = teams[data.iloc[i].HomeTeam].pop()\n",
    "            pcsot_a = teams[data.iloc[i].AwayTeam].pop()\n",
    "        except:\n",
    "            pcsot_h = 0\n",
    "            pcsot_a = 0\n",
    "\n",
    "        PHSOT.append(pcsot_h)\n",
    "        PASOT.append(pcsot_a)\n",
    "        pcsot_h = pcsot_h + HST #Home team's previous goals scored before this match\n",
    "        teams[data.iloc[i].HomeTeam].append(pcsot_h)\n",
    "        pcsot_a = pcsot_a + AST #Away team's previous goals scored before this match\n",
    "        teams[data.iloc[i].AwayTeam].append(pcsot_a)\n",
    "\n",
    "    data_new.loc[:,'PHSOT'] = pd.Series(PHSOT)\n",
    "    data_new.loc[:,'PASOT'] = pd.Series(PASOT)\n",
    "    return data_new\n",
    "\n",
    "#getPreviousShotsOnTarget(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Computing previous fouls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Computing Priors\n",
    "# Calculate Previous Fouls\n",
    "# PHTF = Home teams Previous Fouls, Totaled over season\n",
    "# PATF = Away teams Previous Fouls, Totaled over season\n",
    "\n",
    "def getPreviousTeamFouls(data):\n",
    "    teams = {}\n",
    "    PHTF = [] \n",
    "    PATF = []   \n",
    "\n",
    "    # for each match\n",
    "    for i in range(len(data)):\n",
    "        if (i % 100000 == 0):\n",
    "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
    "                teams[name] = []\n",
    "\n",
    "        HF = data.iloc[i]['HF']\n",
    "        AF = data.iloc[i]['AF']\n",
    "\n",
    "        try:\n",
    "            pcf_h = teams[data.iloc[i].HomeTeam].pop()\n",
    "            pcf_a = teams[data.iloc[i].AwayTeam].pop()\n",
    "        except:\n",
    "            pcf_h = 0\n",
    "            pcf_a = 0\n",
    "\n",
    "        PHTF.append(pcf_h)\n",
    "        PATF.append(pcf_a)\n",
    "        pcf_h = pcf_h + HF #Home team's previous fouls before this match\n",
    "        teams[data.iloc[i].HomeTeam].append(pcf_h)\n",
    "        pcf_a = pcf_a + AF #Away team's previous fouls before this match\n",
    "        teams[data.iloc[i].AwayTeam].append(pcf_a)\n",
    "\n",
    "    data_new.loc[:,'PHTF'] = pd.Series(PHTF)\n",
    "    data_new.loc[:,'PATF'] = pd.Series(PATF)\n",
    "    return data_new\n",
    "\n",
    "#getPreviousTeamFouls(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Computing previous corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Priors\n",
    "# Calculate Previous Corners\n",
    "# PHTC = Home teams Previous Corners, Totaled over season\n",
    "# PATC = Away teams Previous Corners, Totaled over season\n",
    "\n",
    "def getPreviousTeamCorners(data):\n",
    "    teams = {}\n",
    "    PHTC = [] \n",
    "    PATC = []   \n",
    "\n",
    "    # for each match\n",
    "    for i in range(len(data)):\n",
    "        if (i % 100000 == 0):\n",
    "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
    "                teams[name] = []\n",
    "\n",
    "        HC = data.iloc[i]['HC']\n",
    "        AC = data.iloc[i]['AC']\n",
    "\n",
    "        try:\n",
    "            pcc_h = teams[data.iloc[i].HomeTeam].pop()\n",
    "            pcc_a = teams[data.iloc[i].AwayTeam].pop()\n",
    "        except:\n",
    "            pcc_h = 0\n",
    "            pcc_a = 0\n",
    "\n",
    "        PHTC.append(pcc_h)\n",
    "        PATC.append(pcc_a)\n",
    "        pcc_h = pcc_h + HC #Home team's previous corners before this match\n",
    "        teams[data.iloc[i].HomeTeam].append(pcc_h)\n",
    "        pcc_a = pcc_a + AC #Away team's previous corners before this match\n",
    "        teams[data.iloc[i].AwayTeam].append(pcc_a)\n",
    "\n",
    "    data_new.loc[:,'PHTC'] = pd.Series(PHTC)\n",
    "    data_new.loc[:,'PATC'] = pd.Series(PATC)\n",
    "    return data_new\n",
    "\n",
    "#getPreviousTeamCorners(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Computing previous goals before half-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Priors\n",
    "# Calculate Previous Goals before half time\n",
    "# PHTHG = Home teams Previous Goals Before Half Time, Totaled over season\n",
    "# PHTAG = Away teams Previous Goals Before Half Time, Totaled over season\n",
    "\n",
    "def getPreviousHalfTimeGoalsScored(data):\n",
    "    teams = {}\n",
    "    PHTHG = [] \n",
    "    PHTAG = []   \n",
    "\n",
    "    # for each match\n",
    "    for i in range(len(data)):\n",
    "        if (i % 100000 == 0):\n",
    "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
    "                teams[name] = []\n",
    "\n",
    "        HTHG = data.iloc[i]['HTHG']\n",
    "        HTAG = data.iloc[i]['HTAG']\n",
    "\n",
    "        try:\n",
    "            pchtg_h = teams[data.iloc[i].HomeTeam].pop()\n",
    "            pchtg_a = teams[data.iloc[i].AwayTeam].pop()\n",
    "        except:\n",
    "            pchtg_h = 0\n",
    "            pchtg_a = 0\n",
    "\n",
    "        PHTHG.append(pchtg_h)\n",
    "        PHTAG.append(pchtg_a)\n",
    "        pchtg_h = pchtg_h + HTHG #Home team's previous first half goals scored before this match\n",
    "        teams[data.iloc[i].HomeTeam].append(pchtg_h)\n",
    "        pchtg_a = pchtg_a + HTAG #Away team's previous first half goals scored before this match\n",
    "        teams[data.iloc[i].AwayTeam].append(pchtg_a)\n",
    "\n",
    "    data_new.loc[:,'PHTHG'] = pd.Series(PHTHG)\n",
    "    data_new.loc[:,'PHTAG'] = pd.Series(PHTAG)\n",
    "    return data_new\n",
    "\n",
    "#getPreviousHalfTimeGoalsScored(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Compute previous goals after half-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Priors\n",
    "# Calculate Previous Second Half Time Goals in the match\n",
    "# PSHHG = Previous Second Half Time Goals scored by Home team, totaled over season\n",
    "# PSHAG = Previous Second Half Time Goals scored by Away team, totaled over season\n",
    "\n",
    "def getPreviousSecondHalfGoals(data):\n",
    "    teams = {}\n",
    "    PSHHG = [] \n",
    "    PSHAG = []   \n",
    "    \n",
    "    # for each match\n",
    "    for i in range(len(data)):\n",
    "        if (i % 100000 == 0):\n",
    "            for name in data.groupby('HomeTeam').mean().T.columns:\n",
    "                teams[name] = []\n",
    "                \n",
    "        FTHG = data.iloc[i]['FTHG']\n",
    "        FTAG = data.iloc[i]['FTAG']\n",
    "        HTHG = data.iloc[i]['HTHG']\n",
    "        HTAG = data.iloc[i]['HTAG']\n",
    "\n",
    "        try:\n",
    "            shg_h = teams[data.iloc[i].HomeTeam].pop()\n",
    "            shg_a = teams[data.iloc[i].AwayTeam].pop()\n",
    "        except:\n",
    "            shg_h = 0\n",
    "            shg_a = 0\n",
    "\n",
    "        PSHHG.append(shg_h)\n",
    "        PSHAG.append(shg_a)\n",
    "        shg_h = shg_h + (FTHG - HTHG) #Home team's previous second half goals scored before this match\n",
    "        teams[data.iloc[i].HomeTeam].append(shg_h)\n",
    "        shg_a = shg_a + (FTAG - HTAG) #Away team's previous second half goals scored before this match\n",
    "        teams[data.iloc[i].AwayTeam].append(shg_a)\n",
    "\n",
    "    data_new.loc[:,'PSHHG'] = pd.Series(PSHHG)\n",
    "    data_new.loc[:,'PSHAG'] = pd.Series(PSHAG)\n",
    "    return data_new\n",
    "\n",
    "#getPreviousSecondHalfGoals(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def printpriors(data_new):\n",
    "    get_previousFTResults(data_new)\n",
    "    get_PreviousHTResults(data_new)\n",
    "    getPreviousCumulativeGoals(data_new)\n",
    "    getPreviousShots(data_new)\n",
    "    getPreviousShotsOnTarget(data_new)\n",
    "    getPreviousTeamFouls(data_new)\n",
    "    getPreviousTeamCorners(data_new)\n",
    "    getPreviousHalfTimeGoalsScored(data_new)\n",
    "    getPreviousSecondHalfGoals(data_new)\n",
    "    return data_new\n",
    "data_new = printpriors(data_new)\n",
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Final data preprocessing\n",
    "\n",
    "# TODO:\n",
    "# Implement dates using trig - done\n",
    "# Add one hot encoded teams - done\n",
    "# Compute custom features using priors (goals/shots on target, shots on target / total shots, home team fouls / away team fouls)\n",
    "# PHGS/PHSOT, PAGS/PASOT & PHSOT/PHS, PASOT/PAS & PHTF/PATF - done\n",
    "# Implement scaling but don't apply just yet - done\n",
    "# Apply PCA - done\n",
    "\n",
    "dates = data_new.iloc[:, 0:3]\n",
    "month_sin = transformation(dates[\"Month\"])[0]\n",
    "month_cos = transformation(dates[\"Month\"])[1]\n",
    "week_sin = transformation(dates[\"Week\"])[0]\n",
    "week_cos = transformation(dates[\"Week\"])[1]\n",
    "day_sin = transformation(dates[\"Day\"])[0]\n",
    "day_cos = transformation(dates[\"Day\"])[1]\n",
    "\n",
    "teams = pd.DataFrame(home_t.toarray()).add_prefix(\"home_\").join(pd.DataFrame(away_t.toarray()).add_prefix(\"away_\"))\n",
    "\n",
    "# Select only columns that contain priors, can't use in-game stats to predict the future\n",
    "priors = data_new.iloc[:, 21:37]\n",
    "\n",
    "# PHGS_PHSOT is ratio of home goals to home shots on target\n",
    "PHGS_PHSOT = np.where(priors[\"PHSOT\"] != 0, priors[\"PHGS\"]/priors[\"PHSOT\"], 0)\n",
    "# PHGS_PHSOT is ratio of away goals to away shots on target\n",
    "PAGS_PASOT = np.where(priors[\"PASOT\"] != 0, priors[\"PAGS\"]/priors[\"PASOT\"], 0)\n",
    "# PHSOT_PHS is ratio of home shots on target to home shots\n",
    "PHSOT_PHS = np.where(priors[\"PHS\"] != 0, priors[\"PHSOT\"]/ (priors[\"PHS\"] + priors[\"PHSOT\"]), 0)\n",
    "# PASOT_PAS is ratio of away shots on target to away shots\n",
    "PASOT_PAS = np.where(priors[\"PAS\"] != 0, priors[\"PASOT\"]/ (priors[\"PAS\"] + priors[\"PASOT\"]), 0)\n",
    "# PHTF_PATF is ratio of home fouls to away fouls\n",
    "PHTF_PATF = np.where(priors[\"PATF\"] != 0, priors[\"PHTF\"]/priors[\"PATF\"], 0)\n",
    "\n",
    "# Building final dataset\n",
    "X = pd.DataFrame()\n",
    "X[\"month_cos\"] = month_cos\n",
    "X[\"month_sin\"] = month_sin\n",
    "X[\"week_cos\"] = week_cos\n",
    "X[\"week_sin\"] = week_sin\n",
    "X[\"day_cos\"] = day_cos\n",
    "X[\"day_sin\"] = day_sin\n",
    "X = X.join(teams).join(priors)\n",
    "X[\"PHGS_PHSOT\"] = PHGS_PHSOT.tolist()\n",
    "X[\"PAGS_PASOT\"] = PAGS_PASOT.tolist()\n",
    "X[\"PHSOT_PHS\"] = PHSOT_PHS.tolist()\n",
    "X[\"PASOT_PAS\"] = PASOT_PAS.tolist()\n",
    "X[\"PHTF_PATF\"] = PHTF_PATF.tolist()\n",
    "\n",
    "# Not sure if data needs to be scaled so just gonna leave this here\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "# PCA\n",
    "# https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
    "pca = PCA(.95)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "print(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "from tensorflow import keras\n",
    "y_train = keras.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90xVEDPEp5Js"
   },
   "source": [
    "## Methodology Overview\n",
    "<a name='section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOxVov2mqGZ-"
   },
   "source": [
    "## Model Training & Validation\n",
    "<a name='section5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to remove warning to see clearer result\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Implement into pipeline ##\n",
    "# Some general comments:\n",
    "# Gaussian NB is most suitable for non-categorical classification\n",
    "# Based on diagram above (gaussian distributed density plots) the features we use are gaussian distributed however \n",
    "# the teams are not actually gaussian distributed \n",
    "# And the features we use are not conditionally independent as the statistics arent independent (e.g. shots affect\n",
    "# shots on target etc.)\n",
    "# Therefore we expect that the prediction will not be accurate and naives bayes is not suitable\n",
    "\n",
    "#prove calculations and results later\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    " \n",
    "\n",
    "gnb = GaussianNB()\n",
    "y_gnb = gnb.fit(X_train, y_train).predict(X_test)\n",
    "accuracy_score(y_test, y_gnb)\n",
    " \n",
    "\n",
    "#Smoothing parameter scaling\n",
    "# param_grid_nb = {\n",
    "#     'var_smoothing': np.logspace(0,-9, num=100)\n",
    "# }\n",
    "# gnb = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)\n",
    "# y_gnb = gnb.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    " \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_gnb), \": is the accuracy score gnb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Standard, baseline NN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 50\n",
    "#Rename to vanilla\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(128, input_shape=(2,)))\n",
    "model.add(layers.Activation('relu'))\n",
    "# model.add(Dropout(0.1), )\n",
    "model.add(layers.Dense(3))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.1)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "preds = np.argmax(preds, axis=1)\n",
    "accuracy = accuracy_score(y_test, preds) * 100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to make train/test/validation sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Clear clutter from previous Keras session graphs.\n",
    "    clear_session()\n",
    "    n_nodes = trial.suggest_categorical('n_nodes', [100, 1000, 2000, 2500, 3000, 5000])\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 4)\n",
    "    optimizer = trial.suggest_categorical('optimizer',['adam','rmsprop','adagrad', 'sgd'])\n",
    "    drop_out=trial.suggest_discrete_uniform('drop_out', 0.05, 0.5, 0.05)\n",
    "    lr = trial.trial.suggest_loguniform('lr', 0.00001,0.1)\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "      optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adagrad':\n",
    "      optimizer = Adagrad(learning_rate=learning_rate)\n",
    "    elif optimizer =='rmsprop':\n",
    "      optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer =='sgd':\n",
    "      optimizer = SGD(learning_rate=learning_rate)\n",
    "    \n",
    "    model = model = Sequential()\n",
    "    model.add(Input(shape=(37,))) # input size of data_new I guess?\n",
    "    for layer in range(n_layers):\n",
    "        model.add(Dense(n_nodes,\n",
    "                        activation=trial.suggest_categorical(\"activation_1\", [\"relu\", \"linear\", \"sigmoid\"])))\n",
    "        model.add(Dropout(dropout),)\n",
    "        \n",
    "    model.add(Dense(3, \n",
    "                   activation=trial.suggest_categorical(\"activation_1\", [\"relu\", \"linear\", \"sigmoid\"])))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    stopping = EarlyStopping(monitor='val_acc', patience=50)\n",
    "    temp = model.fit(X_train, y_train, validation_data=(X_val, y_val), verbose=0, epochs=200, batch_size=20, callbacks=[stopping])\n",
    "    history.append(temp)\n",
    "    accuracies = np.array(history.history['val_acc'])\n",
    "    \n",
    "    return accuracies[-1]\n",
    "\n",
    "\n",
    "study = optuna.create_study(study_name=study_name, direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "print(study.best_params)\n",
    "print('')\n",
    "print(study.best_value)\n",
    "print('')\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (3458, 3) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11048/2421083194.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgammas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0msvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mpredict_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    160\u001b[0m             X, y = self._validate_data(X, y, dtype=np.float64,\n\u001b[0;32m    161\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m                                        accept_large_sparse=False)\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    806\u001b[0m                         ensure_2d=False, dtype=None)\n\u001b[0;32m    807\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'O'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    846\u001b[0m     raise ValueError(\n\u001b[0;32m    847\u001b[0m         \u001b[1;34m\"y should be a 1d array, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m         \"got an array of shape {} instead.\".format(shape))\n\u001b[0m\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (3458, 3) instead."
     ]
    }
   ],
   "source": [
    "#Using generic SVM to estimate\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "gammas = np.power(2, np.linspace(-15, 3, 10))\n",
    "accuracy_validation = np.empty((5, len(gammas)))\n",
    "\n",
    "for l, gamma in enumerate(gammas):\n",
    "    svm = SVC(kernel='rbf', gamma=gamma, C=100)\n",
    "    svm.fit(X_train, y_train)\n",
    "        \n",
    "    predict_test = svm.predict(X_test)  # test\n",
    "    print(accuracy_score(y_test, predict_test))\n",
    "\n",
    "# SVM = svm.SVC(kernel=\"linear\")   #(kernel=\"poly\", degree=3, coef0=1, C=5) (kernel=\"linear\")\n",
    "# SVM.fit(training_data,y_train)# predict the labels on validation dataset\n",
    "# predictions_SVM = SVM.predict(testing_data)# Use accuracy_score function to get the accuracy\n",
    "# print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, y_test)*100)\n",
    "\n",
    "scores = cross_val_score(SVM, X_whole, y_enc, cv=StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=100))\n",
    "scores.mean()\n",
    "\n",
    "def fineTuneSVM(X_train, y_train):\n",
    "    # define model and parameters\n",
    "    svm = SVC()   \n",
    "    # SVM solves an optimization problem of quadratic order \n",
    "    # link on SVC: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "    # The implementation is based on libsvm. The fit time complexity is more than quadratic with the number of samples which makes it hard to scale to dataset with more than a couple of 10000 samples.\n",
    "    # Therefore, we will stick with basic kernels like linear and rbf which do the job well without sacrificing processing time.\n",
    "    kernel = ['linear', 'rbf'] \n",
    "    # kernel = ['poly', 'rbf', 'sigmoid'] #Advanced kernels \n",
    "    C = [50, 10, 1.0, 0.1, 0.01]\n",
    "    gamma = ['scale']\n",
    "    \n",
    "    # define grid search\n",
    "    grid = dict(kernel=kernel,C=C,gamma=gamma)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    grid_search = GridSearchCV(estimator=svm, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "    grid_result = grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "fineTuneSVM(X_train, y_train)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver = 'liblinear',penalty = 'l1', C = 0.01)\n",
    "y_lr = lr.fit(X_train, y_train).predict(X_test)\n",
    "accuracy_score(y_test,y_lr)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_lr), \": is the accuracy score Logistic Regression\")\n",
    "\n",
    "\n",
    "# Finding best hyperparameters\n",
    "\n",
    "# define models and parameters\n",
    "lr = LogisticRegression()\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear','saga']\n",
    "penalty = ['l1','l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=lr, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "### print all the tested results\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xgboost\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_pipeline = [\n",
    "    ('xgboost' , (Pipeline([('xgboost' ,xgb.XGBClassifier())]))), \n",
    "#     ('nn' , (Pipeline([('nn' , kears_estimator )]))), \n",
    "#     ('...' , (Pipeline([('...' , ... )]))),\n",
    "#     ('...' , (Pipeline([('...' , ... )]))),\n",
    "#     ('...' , (Pipeline([('...' , ... )])))\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for pipe ,model in model_pipeline:\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, preds) * 100\n",
    "    results.append(accuracy)\n",
    "    output = \"%s: %f\" % (pipe, accuracy)\n",
    "    print(output)\n",
    "\n",
    "\n",
    "param_pipeline = Pipeline([(\"classifier\", xgb.XGBClassifier())])\n",
    "model_param_grid = [\n",
    "                {\"classifier\": [xgb.XGBClassifier()],\n",
    "#                  \"classifier__penalty\": ['l2','l1'],\n",
    "#                  \"classifier__C\": np.logspace(0, 4, 10)\n",
    "                 },\n",
    "#                 {\"classifier\": [kears_estimator],\n",
    "#                  \"tfidf__ngram_range\": [(1,1), (1,2), (2,2), (1,3)],\n",
    "#                 \"tfidf__use_idf\": [True, False],\n",
    "#                 \"kc__epochs\": [10, 100, ],\n",
    "#                 \"kc__dense_nparams\": [32, 256, 512],\n",
    "#                 \"kc__init\": [ 'uniform', 'zeros', 'normal', ], \n",
    "#                 \"kc__batch_size\":[2, 16, 32],\n",
    "#                 \"kc__optimizer\":['RMSprop', 'Adam', 'Adamax', 'sgd'],\n",
    "#                 \"kc__dropout\": [0.5, 0.4, 0.3, 0.2, 0.1, 0]\n",
    "#                  },\n",
    "#                 {\"classifier\": [...],\n",
    "#                  \"classifier__...\": [...],\n",
    "#                  },\n",
    "#                 {\"classifier\": [...],\n",
    "#                  \"classifier__...\": [...],\n",
    "#                  },\n",
    "#                 {\"classifier\": [...],\n",
    "#                  \"classifier__...\": [...],\n",
    "#                  }\n",
    "                ]\n",
    "# gridsearch = GridSearchCV(param_pipeline, model_param_grid, cv=5, verbose=1,n_jobs=-1, return_train_score=True)\n",
    "# best_model = gridsearch.fit(X_train,y_train)\n",
    "# print(best_model.best_estimator_)\n",
    "# print(\"The mean accuracy of the model is:\",best_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creating LSTM\n",
    "np.random.seed(42)\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "batch_size = 1\n",
    "# batch_size = 100\n",
    "X_train = np.array(X_train).reshape(-1, batch_size, 2)\n",
    "y_train = np.array(y_train).reshape(-1, batch_size, 3)\n",
    "X_test = np.array(X_test).reshape(-1, batch_size, 2)\n",
    "#Rename to LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(60, input_shape = (1, 2), return_sequences = True))\n",
    "model.add(LSTM(60, input_shape = (1, 2), return_sequences = True))\n",
    "model.add(LSTM(60, input_shape = (1, 2), return_sequences = True))\n",
    "model.add(layers.Dense(3))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "# check standard architecture\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 50, batch_size=50)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "preds = np.argmax(preds, axis=2)\n",
    "accuracy = accuracy_score(y_test, preds) * 100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimising hyperparameters for XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "#xgb_cl = xgb.XGBClassifier(use_label_encoder=False)\n",
    "#xgb_cl.fit(X_train, y_train)\n",
    "\n",
    "# Round 1 values inspired by https://towardsdatascience.com/beginners-guide-to-xgboost-for-classification-problems-50f75aac5390\n",
    "#param_grid = {\n",
    "#    \"max_depth\": [3, 4, 5, 7],\n",
    "#    \"learning_rate\": [0.1, 0.01, 0.05],\n",
    "#    \"gamma\": [0, 0.25, 1],\n",
    "#    \"reg_lambda\": [0, 1, 10],\n",
    "#    \"scale_pos_weight\": [1, 3, 5],\n",
    "#    \"subsample\": [0.8],\n",
    "#    \"colsample_bytree\": [0.5],\n",
    "#}\n",
    "\n",
    "# Init Grid Search\n",
    "#grid_cv = GridSearchCV(xgb_cl, param_grid, n_jobs=-1, cv=3, scoring=\"roc_auc\")\n",
    "\n",
    "# Fit\n",
    "#_ = grid_cv.fit(X_train, y_train)\n",
    "\n",
    "# Round 1 output:\n",
    "#{'colsample_bytree': 0.5,\n",
    "# 'gamma': 0,\n",
    "# 'learning_rate': 0.1,\n",
    "# 'max_depth': 3,\n",
    "# 'reg_lambda': 0,\n",
    "# 'scale_pos_weight': 1,\n",
    "# 'subsample': 0.8}\n",
    "\n",
    "# Round 2:\n",
    "#param_grid = {\n",
    "#    \"max_depth\": [1, 2, 3],\n",
    "#    \"learning_rate\": [0.1, 0.15, 0.2],\n",
    "#    \"gamma\": [0, 0.01, 0.02],\n",
    "#    \"reg_lambda\": [0, 1, 10],\n",
    "#    \"scale_pos_weight\": [1, 3, 5],\n",
    "#    \"subsample\": [0.8],\n",
    "#    \"colsample_bytree\": [0.5],\n",
    "#}\n",
    "\n",
    "#grid_cv_2 = GridSearchCV(xgb_cl, param_grid, n_jobs=-1, cv=3, scoring=\"roc_auc\")\n",
    "\n",
    "#_ = grid_cv_2.fit(X_train, y_train)\n",
    "\n",
    "#grid_cv_2.best_params_\n",
    "\n",
    "# Round 2 output:\n",
    "#{'colsample_bytree': 0.5,\n",
    "# 'gamma': 0,\n",
    "# 'learning_rate': 0.1,\n",
    "# 'max_depth': 1,\n",
    "# 'reg_lambda': 0,\n",
    "# 'scale_pos_weight': 1,\n",
    "# 'subsample': 0.8}\n",
    "\n",
    "# Don't think another round is necessary, now to compute accuracy using these hyperparameters\n",
    "final_cl = xgb.XGBClassifier(\n",
    "    colsample_bytree=0.5,\n",
    "    subsample=0.8,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=1,\n",
    "    reg_lambda=0,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "\n",
    "_ = final_cl.fit(X_train, y_train)\n",
    "\n",
    "preds = final_cl.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, preds)\n",
    "\n",
    "# Accuracy with new hyperparameters is: 0.4824561403508772, accuracy with default hyperparameters is 0.42172740"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_aPyBUwqMAD"
   },
   "source": [
    "## Results\n",
    "<a name='section6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2XDY1oOAyEZ"
   },
   "source": [
    "## Final Predictions on Test Set\n",
    "<a name='section7'></a>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CW1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
